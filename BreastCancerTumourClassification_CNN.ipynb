{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries"
      ],
      "metadata": {
        "id": "iA5iVlQtMrTJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jYuWQ00gMdql"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Dataset"
      ],
      "metadata": {
        "id": "ASJHANi_VWm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "malignant_path = \"/content/Malignant\"\n",
        "benign_path = \"/content/Benign\"\n",
        "image_size = 256\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "j-y0mMc_I0N4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading Dataset"
      ],
      "metadata": {
        "id": "ZLPLEflmVaG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "def load_images_from_folder(folder, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = load_img(img_path, target_size=(image_size, image_size))  # Load image\n",
        "        img_array = img_to_array(img) / 255.0  # Normalize\n",
        "        images.append(img_array)\n",
        "        labels.append(label)  # Assign label\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "QIv77jsYI2hK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load both categories\n",
        "malignant_images, malignant_labels = load_images_from_folder(malignant_path, label=1)\n",
        "benign_images, benign_labels = load_images_from_folder(benign_path, label=0)"
      ],
      "metadata": {
        "id": "iKytK7frJrr1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine and shuffle data\n",
        "X = np.array(malignant_images + benign_images)\n",
        "y = np.array(malignant_labels + benign_labels)"
      ],
      "metadata": {
        "id": "2IsmjzlzJuZn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting the Dataset"
      ],
      "metadata": {
        "id": "YMUWIYOTVe06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset (80% Train, 20% Validation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "K4_z0LKLKFU9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(1000).batch(batch_size)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size)"
      ],
      "metadata": {
        "id": "FRDSqsbvKaU1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network Model"
      ],
      "metadata": {
        "id": "Y3w9mleMOJ9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_custom_model(size=256, dropout_rate=0.5, classes=1):\n",
        "    model = Sequential()\n",
        "    # Block 1\n",
        "    model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001), input_shape=(size, size, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Dropout(0.3))  # Early dropout\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Block 4\n",
        "    model.add(Conv2D(256, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # Block 5\n",
        "    model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "    model.add(Dropout(0.5))  # Strongest dropout here\n",
        "\n",
        "    # Global Average Pooling for feature reduction\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "    # Output Layer (Binary classification - Malignant vs. Benign)\n",
        "    model.add(Dense(classes, activation='sigmoid'))  # Sigmoid for binary classification\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ECk8kUyIMypJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Model\n",
        "model = create_custom_model(size=image_size)"
      ],
      "metadata": {
        "id": "N_ubJAQkKfZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9666573-e8b0-4ede-b6fc-45aefa3a1b26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Vs7V__nRKvJ8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Training"
      ],
      "metadata": {
        "id": "AA4bhdYdVk_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10\n",
        ")"
      ],
      "metadata": {
        "id": "CidgLjksKyGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d1010f-a371-40c0-8553-182f3a469b52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.5400 - loss: 2.3729 - val_accuracy: 0.3797 - val_loss: 2.1953\n",
            "Epoch 2/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - accuracy: 0.5846 - loss: 2.2120 - val_accuracy: 0.3797 - val_loss: 2.2638\n",
            "Epoch 3/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 218ms/step - accuracy: 0.6790 - loss: 2.0943 - val_accuracy: 0.3797 - val_loss: 2.3824\n",
            "Epoch 4/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - accuracy: 0.7366 - loss: 2.0412 - val_accuracy: 0.3797 - val_loss: 2.5130\n",
            "Epoch 5/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 221ms/step - accuracy: 0.6942 - loss: 2.0599 - val_accuracy: 0.3797 - val_loss: 2.7166\n",
            "Epoch 6/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6993 - loss: 2.0698 - val_accuracy: 0.3797 - val_loss: 2.8946\n",
            "Epoch 7/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - accuracy: 0.7495 - loss: 2.0280 - val_accuracy: 0.3797 - val_loss: 3.1169\n",
            "Epoch 8/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.7051 - loss: 2.1109 - val_accuracy: 0.3797 - val_loss: 3.2705\n",
            "Epoch 9/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.7707 - loss: 1.9390 - val_accuracy: 0.3797 - val_loss: 3.5369\n",
            "Epoch 10/10\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - accuracy: 0.7810 - loss: 1.9603 - val_accuracy: 0.3797 - val_loss: 3.8164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model on Validation Data\n",
        "val_preds = model.predict(val_dataset)\n",
        "val_preds = (val_preds > 0.5).astype(int)  # Convert probabilities to binary class"
      ],
      "metadata": {
        "id": "sBlL1_CVLaFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e878029e-b425-4bc3-f3c2-22d934284d5e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 580ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Report"
      ],
      "metadata": {
        "id": "ggfs4TMgVpxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Classification Report\n",
        "report = classification_report(y_val, val_preds, target_names=[\"Benign\", \"Malignant\"])\n",
        "print(report)"
      ],
      "metadata": {
        "id": "4TKhYGc5Ld81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade6770a-60c9-4d77-ec7f-52a4ef827a3c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.00      0.00      0.00        49\n",
            "   Malignant       0.38      1.00      0.55        30\n",
            "\n",
            "    accuracy                           0.38        79\n",
            "   macro avg       0.19      0.50      0.28        79\n",
            "weighted avg       0.14      0.38      0.21        79\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}